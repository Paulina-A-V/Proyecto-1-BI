{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1 - Etapa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn import tree\n",
    "import sklearn as sklearn\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/paulinaarrazola/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/paulinaarrazola/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading stopwords-es: Package 'stopwords-es' not\n",
      "[nltk_data]     found in index\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/paulinaarrazola/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('stopwords-es')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "news=pd.read_csv(\"./fake_news.csv\", sep=\";\")\n",
    "data= news.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57063, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51307</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>La Mesa de la Asamblea de Madrid aprueba que C...</td>\n",
       "      <td>Toda la oposición había solicitado esta inicia...</td>\n",
       "      <td>22/03/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Celaá critica al Iniciativa vers per Catalunya...</td>\n",
       "      <td>La demanda social es un criterio que, desde mi...</td>\n",
       "      <td>02/03/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>La derecha coincide en su estrategia contra la...</td>\n",
       "      <td>El efecto llamada es el comodín que utiliza la...</td>\n",
       "      <td>09/12/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31685</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>José Primo de Rivera asume Política Territoria...</td>\n",
       "      <td>La nueva ministra de Política Territorial y po...</td>\n",
       "      <td>10/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37218</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Madrid vira a la derecha y Barcelona avanza ha...</td>\n",
       "      <td>PP y Ciudadanos miran a Vox para hacerse con e...</td>\n",
       "      <td>28/05/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label                                             Titulo  \\\n",
       "51307  ID      0  La Mesa de la Asamblea de Madrid aprueba que C...   \n",
       "15995  ID      0  Celaá critica al Iniciativa vers per Catalunya...   \n",
       "14887  ID      1  La derecha coincide en su estrategia contra la...   \n",
       "31685  ID      0  José Primo de Rivera asume Política Territoria...   \n",
       "37218  ID      1  Madrid vira a la derecha y Barcelona avanza ha...   \n",
       "\n",
       "                                             Descripcion       Fecha  \n",
       "51307  Toda la oposición había solicitado esta inicia...  22/03/2018  \n",
       "15995  La demanda social es un criterio que, desde mi...  02/03/2019  \n",
       "14887  El efecto llamada es el comodín que utiliza la...  09/12/2020  \n",
       "31685  La nueva ministra de Política Territorial y po...  10/07/2021  \n",
       "37218  PP y Ciudadanos miran a Vox para hacerse con e...  28/05/2019  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, nos encontramos con cinco variables dentro del dataset. En primer lugar, encontramos una columna \"Label\" la cual si bien no esta bien definido el nombre podemos concluir que indica la veracidad del registro asociado. Luego, hallamos variables de informacion sobre la noticia (Titulo, Descripcion y Fecha). Finalmente, tenemos la columna \"ID\", que en todas las filas analizadas aparece simplemente como \"ID\", en lugar de un identificador único. Esto sugiere que la columna podría no aportar valor al análisis y que probablemente deba ser eliminada para evitar información redundante o errónea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entendimiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             object\n",
       "Label           int64\n",
       "Titulo         object\n",
       "Descripcion    object\n",
       "Fecha          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no se realiza \".describe\" porque no tiene sentido en este caso porque como todos los datos son de categoricos menos el id no tiene sentido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Label           0\n",
       "Titulo         16\n",
       "Descripcion     0\n",
       "Fecha           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se decide no quitar aquellos registros sin titulo dado que las descripciones pueden contener información valiosa, ademas, se pueden identificar las noticias bajo su id o manejar los valores nulos de otra manera como relleno o NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "1    58.107706\n",
      "0    41.892294\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Saber cuantas de las noticias que tenemos son falsas. DESCRIBIR RESULTADOS\n",
    "porcentajes = data['Label'].value_counts(normalize=True) * 100\n",
    "print(porcentajes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m     17\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspanish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[1;32m     20\u001b[0m fdist \u001b[38;5;241m=\u001b[39m FreqDist(words)\n\u001b[1;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" from nltk.probability import FreqDist\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select 5 random indices within the valid range\n",
    "random_indices = random.sample(range(data.shape[0]), 5)\n",
    "text = ' '.join(data['Descripcion'][i] for i in random_indices)\n",
    "\n",
    "fdist = FreqDist(text.split())\n",
    "\n",
    "plt.figure(figsize=(12, 6))  \n",
    "fdist.plot(25, cumulative=False)\n",
    "plt.show() \"\"\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "words = [word for word in text.split() if word.lower() not in stop_words]\n",
    "\n",
    "fdist = FreqDist(words)\n",
    "plt.figure(figsize=(12, 6))\n",
    "fdist.plot(25, cumulative=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seleccionan 5 descripciones de registros al azar para encontrar las palabras más comunes en estos pedazos y tener un primer entendimiento de las palabras más predominantes que podemos llegar a encontrar, tambien se realiza un filtro para evitar articulos y preposiciones y asi generar palabras mas significativas. Como podemos observar, las palabras que mas se resaltan estam relacionadas con politica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 57063\n",
       "unique                                                49638\n",
       "top       La Fundación En Acción ha participado con Públ...\n",
       "freq                                                      7\n",
       "Name: Descripcion, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Descripcion'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 1\n",
       "Label              2\n",
       "Titulo         51604\n",
       "Descripcion    49638\n",
       "Fecha           2271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resgistros totales: 57063\n",
    "Registros unicos: 49638\n",
    "13% de las descripciones registros son duplicados\n",
    "Hay títulos que comparten la misma descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripciones vacias: 0\n"
     ]
    }
   ],
   "source": [
    "# Buscamos registros vacios\n",
    "empty_texts = data[data['Descripcion'].str.strip() == '']\n",
    "print(f\"Descripciones vacias: {len(empty_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan los registros de las descripciones que estan repetidos porque el motor se puede confundir o puede aumentar el bias (explciar mejor por que). Se deja la primera ocurrencia. Se elimina duplicados por que no coinciden los duplicados entre columnas y hay algunas que si tiene sentido la duplicidad (la fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49638, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset=['Descripcion'], keep='first')\n",
    "#confirmamos que se hayan eliminado los duplicados\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "#Se hace una isnpeccion visual para identificar caracteres especiales que reemplazan otra letra y se incluyen en el diccionario \n",
    "# para corregirlo y no perder esas palabras cuando eliminemos los caracteres especiales\n",
    "\n",
    "mapa_reemplazo= {\n",
    "    \"√°\": \"a\",\n",
    "    \"√©\": \"e\",\n",
    "    \"√≠\": \"i\",\n",
    "    \"√≥\": \"o\",\n",
    "    \"√º\":\"ú\",\n",
    "    \"√±\": \"ñ\",\n",
    "}\n",
    "\n",
    "def correct_common_replacements(text):\n",
    "\n",
    "    for wrong, right in mapa_reemplazo.items():\n",
    "        text = text.replace(wrong, right)\n",
    "    return text\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "          new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "          new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "  \n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_integers(words):\n",
    "  \n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r\"\\b\\d+\\b\", \"\", word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words, stopwords=stopwords.words('spanish')):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def preprocessing(words):\n",
    "    text = ' '.join(words)\n",
    "    text = correct_common_replacements(text)\n",
    "    words = text.split()\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_integers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una correción de caracteres especiales ya que algunas codificaciones defectuosas pueden hacer que caracteres acentuados se conviertan en símbolos extraños (√°, √©, etc.). Luego, Ese hace eliminación de caracteres no ASCII convirtiendo caracteres con tildes en su versión sin tilde utilizando, esto es útil porque en algunos modelos, la misma palabra con y sin tilde podría ser tratada como diferente. Después,  se hace eliminación de puntación, números, palabras vacias y conversión a minusculas. Se realizan estas funciones con el objetivo de mejorar la calidad del texto antes del análisis, reducir el ruido eliminando información irrelevante y evitar problemas de codificación con caracteres especiales.\n",
    "\n",
    "\n",
    "EXPLICAR TODOS LOS PASOS ANTERIORES (ESPECIFICAMENTE POR QUE SE HACEN MAS QUE COMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tokenización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza tokenización para estandatizar el analisis, eliminar el ruido y poder representar el texto de mejor manera. Es importante denotar que se hicieron uso de las funciones previemente observadas para la reduccion de ruido. Es imprecindible este paso para mejorar la calidad de los datos antes de analizarlos o usarlos en los modelos.\n",
    "\n",
    "EXPLICAR NECESIDAD Y DECIR QUE SE LE APLICAN LAS FUNCIONES DE ARRIBA PARA REDUCIR EL RUIDO (DESARROLLAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "data['Descripcion'] = data['Descripcion'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una expansión de contracciones con el fin de evitar la perdida de información al convertir palabras contraídas en su versión completa, mejorar la calidad de los datos para modelos y reducir la ambiguedad en el analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>02/06/2023</td>\n",
       "      <td>[diario, britanico, publico, pasado, jueves, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>01/10/2023</td>\n",
       "      <td>[revelan, gobierno, negocio, liberacion, mirel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>25/04/2022</td>\n",
       "      <td>[valencianismo, convoca, castello, fiesta, gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>[politica, igual, negociar, empresarios, negoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>09/03/2018</td>\n",
       "      <td>[entrevista, punt, avui, lider, jxcat, desdram...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Label                                             Titulo  \\\n",
       "0  ID      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1  ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3  ID      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4  ID      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion       Fecha  \\\n",
       "0  El diario británico publicó este pasado jueves...  02/06/2023   \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...  01/10/2023   \n",
       "2  El valencianismo convoca en Castelló su fiesta...  25/04/2022   \n",
       "3  En política, igual que hay que negociar con lo...  03/01/2022   \n",
       "4  En una entrevista en El Punt Avui, el líder de...  09/03/2018   \n",
       "\n",
       "                                               words  \n",
       "0  [diario, britanico, publico, pasado, jueves, e...  \n",
       "1  [revelan, gobierno, negocio, liberacion, mirel...  \n",
       "2  [valencianismo, convoca, castello, fiesta, gra...  \n",
       "3  [politica, igual, negociar, empresarios, negoc...  \n",
       "4  [entrevista, punt, avui, lider, jxcat, desdram...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['words'] = data['Descripcion'].apply(word_tokenize).apply(preprocessing)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tokeniza el campo descripcion para convertir el texto en una lista de palabras y se aplica la funcion preprocessing() para limpiar y normalizar cada token. Como podemos ver en la columna \"words\", contiene una versión limpia y lista del texto para análisis facilitando tareas como detección de noticias falsas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalización es un paso clave en este caso para el procesamiento de lenguaje natural, ya que reduce la variabilidad del texto sin perder su significado, lo que ayuda a mejorar la calidad del análisis. Cuando se trabaja con datos de texto, se pueden presentarse múltiples variaciones de una misma palabra que deben tratarse como equivalentes.\n",
    "\n",
    "EXPLICAR NECESIDAD Y PROCESO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>02/06/2023</td>\n",
       "      <td>[diari, britan, public, pas, juev, editorial, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>01/10/2023</td>\n",
       "      <td>[revel, gobiern, negoci, liber, mirel, cambi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>25/04/2022</td>\n",
       "      <td>[valencian, convoc, castell, fiest, grand, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>[polit, igual, negoci, empresari, negoci, grup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>09/03/2018</td>\n",
       "      <td>[entrev, punt, avui, lid, jxcat, desdramatiz, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Label                                             Titulo  \\\n",
       "0  ID      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1  ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2  ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3  ID      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4  ID      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "\n",
       "                                         Descripcion       Fecha  \\\n",
       "0  El diario británico publicó este pasado jueves...  02/06/2023   \n",
       "1  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...  01/10/2023   \n",
       "2  El valencianismo convoca en Castelló su fiesta...  25/04/2022   \n",
       "3  En política, igual que hay que negociar con lo...  03/01/2022   \n",
       "4  En una entrevista en El Punt Avui, el líder de...  09/03/2018   \n",
       "\n",
       "                                               words  \n",
       "0  [diari, britan, public, pas, juev, editorial, ...  \n",
       "1  [revel, gobiern, negoci, liber, mirel, cambi, ...  \n",
       "2  [valencian, convoc, castell, fiest, grand, con...  \n",
       "3  [polit, igual, negoci, empresari, negoci, grup...  \n",
       "4  [entrev, punt, avui, lid, jxcat, desdramatiz, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems + lemmas\n",
    "\n",
    "data['words'] = data['words'].apply(stem_and_lemmatize) #Aplica lematización y eliminación de prefijos y sufijos.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica stemming y lemmatization a las palabras de la columna 'words' del dataset con el objetivo de reducir las palabras a su forma base.\n",
    "\n",
    "La función stem_words(words) usa SnowballStemmer para recortar palabras eliminando sufijos y prefijos. Es importante entender que el stemming puede generar palabras sin sentido, sin embargo, reduce la dimensionalidad del texto.\n",
    "\n",
    "La función lemmatize_verbs(words) usa WordNetLemmatizer para convertir verbos a su forma base.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Selección de campos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá si explicar pasito a pasito en palabras cortas que se hizo. Ver ejemplo en gitlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>'The Guardian' va con Sánchez: 'Europa necesit...</td>\n",
       "      <td>El diario británico publicó este pasado jueves...</td>\n",
       "      <td>02/06/2023</td>\n",
       "      <td>diari britan public pas juev editorial proxim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...</td>\n",
       "      <td>01/10/2023</td>\n",
       "      <td>revel gobiern negoci liber mirel cambi otorg p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El 'Ahora o nunca' de Joan Fuster sobre el est...</td>\n",
       "      <td>El valencianismo convoca en Castelló su fiesta...</td>\n",
       "      <td>25/04/2022</td>\n",
       "      <td>valencian convoc castell fiest grand conmemor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Iglesias alienta a Yolanda Díaz, ERC y EH Bild...</td>\n",
       "      <td>En política, igual que hay que negociar con lo...</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>polit igual negoci empresari negoci grup parla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>Puigdemont: 'No sería ninguna tragedia una rep...</td>\n",
       "      <td>En una entrevista en El Punt Avui, el líder de...</td>\n",
       "      <td>09/03/2018</td>\n",
       "      <td>entrev punt avui lid jxcat desdramatiz posibl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57058</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El Defensor del Pueblo reclama a la Comunidad ...</td>\n",
       "      <td>El gobierno regional han indicado que la atenc...</td>\n",
       "      <td>08/06/2021</td>\n",
       "      <td>gobiern regional indic atencion dia inclu aten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57059</th>\n",
       "      <td>ID</td>\n",
       "      <td>0</td>\n",
       "      <td>El EQUO plantea ceder la presidencia de la Com...</td>\n",
       "      <td>Si la higiene democrática nos lleva a esa exig...</td>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>si higien democrat llev exigent ten pas person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57060</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Alberto Garzón: 'Que los Borbones son unos lad...</td>\n",
       "      <td>El coordinador federal de IU asegura que la mo...</td>\n",
       "      <td>12/07/2018</td>\n",
       "      <td>coordin federal iu asegur monarqui putrefact c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57061</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Vox exige entrar en el Gobierno de Castilla y ...</td>\n",
       "      <td>Santiago Abascal: Vox tiene el derecho y el de...</td>\n",
       "      <td>13/02/2022</td>\n",
       "      <td>santiag abascal vox derech deb form gobiern ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57062</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Unas 300 personas protestan contra la visita d...</td>\n",
       "      <td>Los Mossos dEsquadra han blindado los alrededo...</td>\n",
       "      <td>09/10/2020</td>\n",
       "      <td>moss desquadr blind alrededor estacion franci ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49638 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Label                                             Titulo  \\\n",
       "0      ID      1  'The Guardian' va con Sánchez: 'Europa necesit...   \n",
       "1      ID      0  REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...   \n",
       "2      ID      1  El 'Ahora o nunca' de Joan Fuster sobre el est...   \n",
       "3      ID      1  Iglesias alienta a Yolanda Díaz, ERC y EH Bild...   \n",
       "4      ID      0  Puigdemont: 'No sería ninguna tragedia una rep...   \n",
       "...    ..    ...                                                ...   \n",
       "57058  ID      1  El Defensor del Pueblo reclama a la Comunidad ...   \n",
       "57059  ID      0  El EQUO plantea ceder la presidencia de la Com...   \n",
       "57060  ID      1  Alberto Garzón: 'Que los Borbones son unos lad...   \n",
       "57061  ID      1  Vox exige entrar en el Gobierno de Castilla y ...   \n",
       "57062  ID      1  Unas 300 personas protestan contra la visita d...   \n",
       "\n",
       "                                             Descripcion       Fecha  \\\n",
       "0      El diario británico publicó este pasado jueves...  02/06/2023   \n",
       "1      REVELAN QUE EL GOBIERNO NEGOCIO LA LIBERACIÓN ...  01/10/2023   \n",
       "2      El valencianismo convoca en Castelló su fiesta...  25/04/2022   \n",
       "3      En política, igual que hay que negociar con lo...  03/01/2022   \n",
       "4      En una entrevista en El Punt Avui, el líder de...  09/03/2018   \n",
       "...                                                  ...         ...   \n",
       "57058  El gobierno regional han indicado que la atenc...  08/06/2021   \n",
       "57059  Si la higiene democrática nos lleva a esa exig...  08/09/2020   \n",
       "57060  El coordinador federal de IU asegura que la mo...  12/07/2018   \n",
       "57061  Santiago Abascal: Vox tiene el derecho y el de...  13/02/2022   \n",
       "57062  Los Mossos dEsquadra han blindado los alrededo...  09/10/2020   \n",
       "\n",
       "                                                   words  \n",
       "0      diari britan public pas juev editorial proxim ...  \n",
       "1      revel gobiern negoci liber mirel cambi otorg p...  \n",
       "2      valencian convoc castell fiest grand conmemor ...  \n",
       "3      polit igual negoci empresari negoci grup parla...  \n",
       "4      entrev punt avui lid jxcat desdramatiz posibl ...  \n",
       "...                                                  ...  \n",
       "57058  gobiern regional indic atencion dia inclu aten...  \n",
       "57059  si higien democrat llev exigent ten pas person...  \n",
       "57060  coordin federal iu asegur monarqui putrefact c...  \n",
       "57061  santiag abascal vox derech deb form gobiern ca...  \n",
       "57062  moss desquadr blind alrededor estacion franci ...  \n",
       "\n",
       "[49638 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['words'] = data['words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"Descripcion\"], data[\"Label\"], test_size = 0.2, stratify = data[\"Label\"], random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Random Forest (Paulina Arrázola)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
